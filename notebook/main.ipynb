{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e663dbb2",
   "metadata": {},
   "source": [
    "# Predicting the gender of lead actors in Hollywood films\n",
    "\n",
    "This notebook guides you step by step through the process of analyzing film data \n",
    "and building classification models to predict whether the lead actor in a movie is male or female. \n",
    "\n",
    "We'll explore the data, engineer some features, tune different machine learning models, \n",
    "and finally choose the best one to make our predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0bbf6",
   "metadata": {},
   "source": [
    "# Importing libraries and setting up the environment\n",
    "\n",
    "Before we dive into the analysis and modeling, we start by importing all the necessary Python libraries.\n",
    "\n",
    "1. **Data handling**\n",
    "    - `pandas` and `numpy` for loading and manipulating datasets.\n",
    "\n",
    "2. **Visualization**\n",
    "    - `matplotlib` and `seaborn` to create plots and explore data distributions.\n",
    "\n",
    "3. **Machine learning**\n",
    "    - `scikit-learn` for implementing various classification algorithms,\n",
    "      preprocessing data, and evaluating model performance.\n",
    "\n",
    "We also set a random seed to make sure our experiments are reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.preprocessing as skl_pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.discriminant_analysis as skl_da\n",
    "import sklearn.neighbors as skl_nb\n",
    "import sklearn.model_selection as skl_ms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e1d80",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "We start by loading the training and test datasets using `pandas`. This gives us an initial idea of the dataset size and structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1563c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "print(train.shape)\n",
    "test = pd.read_csv('../data/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a4db16",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "To prepare our data for modeling, we create a few new features:\n",
    "\n",
    "- **Co-lead words**: estimates the words spoken by the co-lead as a proportion of total words.\n",
    "- **Percentage of words spoken by female and male actors**: normalizes the dialogue counts.\n",
    "\n",
    "We also drop the columns `Total words` and `Difference in words lead and co-lead` since their information is now captured in the new features.\n",
    "We apply the same transformations to both the training and test datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3911e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature selection and engineering ###\n",
    "\n",
    "train[\"Co-lead words\"] = (\n",
    "    (train[\"Number of words lead\"] - train[\"Difference in words lead and co-lead\"]) \n",
    "    / train[\"Total words\"]\n",
    ")\n",
    "train[\"percentage female\"] = train[\"Number words female\"] / train[\"Total words\"]\n",
    "train[\"percentage male\"] = train[\"Number words male\"] / train[\"Total words\"]\n",
    "\n",
    "train = train.drop([\"Difference in words lead and co-lead\", \"Total words\"], axis=1)\n",
    "\n",
    "# Apply the same transformations to the test data\n",
    "test[\"Co-lead words\"] = (\n",
    "    (test[\"Number of words lead\"] - test[\"Difference in words lead and co-lead\"])\n",
    "    / test[\"Total words\"]\n",
    ")\n",
    "test[\"percentage female\"] = test[\"Number words female\"] / test[\"Total words\"]\n",
    "test[\"percentage male\"] = test[\"Number words male\"] / test[\"Total words\"]\n",
    "\n",
    "test = test.drop([\"Difference in words lead and co-lead\", \"Total words\"], axis=1)\n",
    "\n",
    "X = train.drop(\"Lead\", axis=1)\n",
    "y = train[\"Lead\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e0733",
   "metadata": {},
   "source": [
    "# Finding the optimal *k* for k-Nearest Neighbors\n",
    "\n",
    "To tune our k-NN model, we run multiple cross-validation loops over a range of *k* values (from 1 to 200).\n",
    "This helps us understand how the choice of *k* affects prediction accuracy.\n",
    "\n",
    "We repeat this process several times to get a stable estimate, then plot the average accuracy\n",
    "to identify the best *k* value for our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "### KNN METHOD ###\n",
    "# Cross-validation with repeated splitting to find the optimal k\n",
    "\n",
    "n_runs = 10\n",
    "K = np.arange(1, 200)\n",
    "classification = np.zeros((n_runs, len(K)))\n",
    "\n",
    "for i in range(n_runs):\n",
    "    x_train, x_val, y_train, y_val = skl_ms.train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    \n",
    "    # Rescale data with Standard Scaler\n",
    "    scaler = skl_pre.StandardScaler().fit(x_train)\n",
    "    \n",
    "    for j, k in enumerate(K):\n",
    "        model = skl_nb.KNeighborsClassifier(n_neighbors=k)\n",
    "        model.fit(scaler.transform(x_train), y_train)\n",
    "        prediction = model.predict(scaler.transform(x_val))\n",
    "        classification[i, j] = np.mean(prediction == y_val)\n",
    "\n",
    "average_classification = np.mean(classification, axis=0)\n",
    "\n",
    "optimal_k_index = np.argmax(average_classification)\n",
    "optimal_k = K[optimal_k_index]\n",
    "optimal_accuracy = average_classification[optimal_k_index]\n",
    "\n",
    "print(f\"The optimal k is {optimal_k} with an average accuracy of {optimal_accuracy:.4f}\")\n",
    "\n",
    "plt.scatter(K, average_classification)\n",
    "plt.xlabel(\"k (number of neighbors)\")\n",
    "plt.ylabel(\"Average classification accuracy\")\n",
    "plt.title(\"Finding the optimal k for k-NN\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d2c89",
   "metadata": {},
   "source": [
    "# Tuning Random Forest hyperparameters\n",
    "\n",
    "Next, we tune the hyperparameters of the Random Forest classifier to improve its performance.\n",
    "We use `GridSearchCV` to explore different values for:\n",
    "\n",
    "- `n_estimators`: the number of trees in the forest.\n",
    "- `max_leaf_nodes`: the maximum number of leaf nodes in each tree.\n",
    "\n",
    "We use 5-fold cross-validation to evaluate the performance of each parameter combination and\n",
    "print out the best configuration along with its cross-validated accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b61c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': list(range(10, 100, 10)),\n",
    "    'max_leaf_nodes': list(range(10, 100, 10)),\n",
    "    'random_state': [1]\n",
    "}\n",
    "\n",
    "grid_search = skl_ms.GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(f\"Best cross-validated accuracy: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed5102",
   "metadata": {},
   "source": [
    "# Comparing different models with k-fold cross-validation\n",
    "\n",
    "To understand how our selected models perform relative to each other, we run a k-fold cross-validation \n",
    "process (with 5 folds) and calculate the validation error for each model. This gives us a clearer picture \n",
    "of which models are more stable and accurate on unseen data.\n",
    "\n",
    "We include:\n",
    "\n",
    "- Quadratic Discriminant Analysis (QDA)\n",
    "- k-Nearest Neighbors with the optimal *k* we found\n",
    "- Random Forest with tuned hyperparameters\n",
    "\n",
    "Finally, we plot a boxplot of the validation errors for each model to visualize their performance spread.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to compare\n",
    "models = []\n",
    "models.append(skl_da.QuadraticDiscriminantAnalysis())\n",
    "models.append(skl_nb.KNeighborsClassifier(n_neighbors=optimal_k))\n",
    "models.append(RandomForestClassifier(\n",
    "    n_estimators=grid_search.best_params_['n_estimators'],\n",
    "    max_leaf_nodes=grid_search.best_params_['max_leaf_nodes'],\n",
    "    random_state=1\n",
    "))\n",
    "\n",
    "# k-fold cross-validation\n",
    "n_fold = 5\n",
    "misclassification = np.zeros((n_fold, len(models)))\n",
    "cv = skl_ms.KFold(n_splits=n_fold, random_state=2, shuffle=True)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(cv.split(X)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    for j, model in enumerate(models):\n",
    "        scaler = skl_pre.StandardScaler().fit(X_train)\n",
    "        model.fit(scaler.transform(X_train), y_train)\n",
    "        prediction = model.predict(scaler.transform(X_val))\n",
    "        misclassification[i, j] = np.mean(prediction != y_val)\n",
    "\n",
    "# Boxplot to compare validation errors\n",
    "plt.boxplot(misclassification)\n",
    "plt.xticks(np.arange(len(models)) + 1, [type(model).__name__ for model in models])\n",
    "plt.ylabel(\"Validation Error\")\n",
    "plt.title(\"Model comparison with k-fold cross-validation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffb4df",
   "metadata": {},
   "source": [
    "# Training the final model and generating predictions\n",
    "\n",
    "Based on our cross-validation results, we choose the Quadratic Discriminant Analysis (QDA) model \n",
    "as our final model for production. We train it on the entire training dataset to leverage all available data.\n",
    "\n",
    "Finally, we predict on the test set and save the results in a CSV file named `predictions.csv`,\n",
    "formatted as required for submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final QDA model trained on full training data\n",
    "final_model = skl_da.QuadraticDiscriminantAnalysis()\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Make predictions on test set\n",
    "final_predictions = final_model.predict(test)\n",
    "\n",
    "# Convert to 0/1: 0 for Male, 1 for Female\n",
    "final_predictions = np.where(final_predictions == \"Male\", 0, 1).reshape(1, -1)\n",
    "\n",
    "# Save to predictions.csv without index and header\n",
    "pd.DataFrame(final_predictions).to_csv(\"../results/predictions.csv\", index=False, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
